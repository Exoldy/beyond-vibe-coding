# Глава 2. Искусство промта: Как базарить с ИИ, чтобы он тебя понял

В вайб-кодинге промты — это новый исходный код.

То, как ты доносишь свои хотелки до ИИ, напрямую влияет на качество кода, который он выплюнет. Написание годного промта — это и искусство, и наука, которую часто называют промт-инжинирингом. Эта глава вооружит тебя техниками, чтобы выжать максимум из твоего кремниевого ассистента. Мы начнем с базы — почему промты вообще важны, а затем залезем в ящик с инструментами: от простых приемов до продвинутых техник. Научившись крафтить эффективные запросы и итеративно их допиливать (Рисунок 2-1), ты сможешь кодить в тандеме с ИИ гораздо быстрее и точнее.

> [!NOTE]
> **Image Missing**
> *Рисунок 2-1. Иллюстрация чат-бота, помогающего с кодом. Разработчик и ИИ ведут диалог: разраб кидает инструкции или вопросы (промты), а ИИ отвечает кодом или советами. Грамотная коммуникация через четкие промты — ключ к получению рабочего и полезного кода.*

## Основы промт-инжиниринга

Если вайб-кодинг — это разговор между тобой и моделью, то промт-инжиниринг — это умение говорить на языке ИИ, чтобы получить нормальный результат. Грамотно составленный промт может стать разницей между бесполезным куском забагованного кода и идеальным решением, попавшим точно в цель. Овладеть этим навыком — значит понять, как направлять ИИ, как давать контекст и как итерировать, когда первый ответ оказался "ну такое".

Когда ты программируешь с ИИ, ты, по сути, программируешь *через* ИИ, используя естественный язык. Твой промт — это высокоуровневый язык программирования, который интерпретатор ИИ транслирует в реальный код. И точно так же, как выхлоп компилятора зависит от качества исходников, выхлоп ИИ зависит от качества промта.

Почему промты так важны? LLM-ки, при всей их крутости, мысли читать не умеют. Они реагируют только на то, что им скормили. Мутные или криво сформулированные промты ведут к левому или нерабочему коду, в то время как четкий и конкретный запрос может выдать решение в яблочко с первой попытки. В традиционном кодинге ты тратишь время на продумывание алгоритмов и написание синтаксиса; в вайб-кодинге ты тратишь время на то, чтобы сформулировать требования для ИИ. Это сдвиг парадигмы того, что значит "писать код": ты можешь накатать абзац текста вместо функции, но логика и точность всё равно должны быть железными.

Представь, что пишешь доку или user story для очень душного джуна-буквоеда. Он сделает ровно (и только) то, что написано в документации. У него вагон знаний, но здравого смысла — ноль, только паттерны, которые он где-то видел. Если твои инструкции (промты) оставляют простор для интерпретации, ИИ заполнит пробелы так, как тебе точно не понравится. Поэтому учиться общаться с ИИ сейчас так же важно, как раньше было учить синтаксис языка.

Еще одна причина важности промтов — воспроизводимость и задел на будущее. Если ты нашел промт, который стабильно генерит хороший код для определенного паттерна или задачи, этот промт становится ценным активом (почти как сниппет или шаблон). Ты можешь сохранить его или переиспользовать в похожих ситуациях. В командах разработчики могут шарить эффективные промты друг с другом, так же как они делятся лучшими практиками кодинга.

И наконец, по мере того как модели становятся умнее и интегрированнее, они позволяют всё более сложные взаимодействия. Умение грамотно промтить позволит тебе быстро осваивать новые фичи. Например, некоторые продвинутые системы позволяют прикреплять обширные инструкции или скармливать целые доки в качестве контекста. Понимание того, как структурировать этот входной поток — ключ к использованию всей этой мощи.

Так что относись к написанию промтов как к новому обязательному скиллу. Во многих смыслах промтинг — это и есть программирование. Главное отличие в том, что ты пишешь на языке (типа английского), который ИИ конвертирует в код. Но тебе всё равно нужно быть четким, логичным и предусматривать граничные случаи (edge cases) в своем описании.

## Конкретика и ясность: Пишем промты, которые работают

Одно из золотых правил промтинга (которое я разверну подробнее в Главе 3) — быть конкретным и четко понимать, чего ты хочешь. В отличие от коллеги-человека, ИИ ни черта не понимает твою конечную цель за пределами тех слов, что ты написал. Типичная ошибка новичка — кинуть ИИ супер-абстрактный промт типа "Сделай веб-сайт" и ждать магии. ИИ лучше работает с конкретными деталями.

Всегда исходи из того, что он не знает о твоем проекте ничего, кроме того, что ты ему дал. Включай релевантные детали: язык программирования, фреймворк, библиотеки, а также конкретную функцию или кусок, над которым работаешь. Если вылезла ошибка — дай точный текст ошибки и опиши, что код *должен* был сделать. Любая муть или недосказанность может привести к непредсказуемым результатам.

Например, вместо "Напиши функцию сортировки", скажи:

> Напиши функцию на Python `sort_by_lastname(customers)`, которая принимает список записей клиентов (у каждой есть поля `first_name` и `last_name`) и возвращает список, отсортированный по `last_name` в алфавитном порядке. Добавь краткий docstring и обработай случай отсутствия фамилии, считая её пустой строкой.

Этот промт задает четкие ожидания по языку (Python), имени и назначению функции, структуре входных данных, ключу сортировки, доп. требованиям (docstring) и граничному случаю. Скорее всего, он выдаст ровно то, что тебе нужно, или очень близко к этому. По сути, думай как составитель техзадания: чем точнее ты опишешь задачу, тем меньше ИИ придется гадать на кофейной гуще и тем меньше правок тебе придется вносить.

Стратегии для повышения конкретики:

### Укажи язык или окружение
Если тебе нужно решение на JavaScript, так и скажи: "Напиши JavaScript функцию..." вместо просто "Напиши функцию...". Если это под конкретный фреймворк или версию, уточни ("Используя React Hooks..." или "на Python 3...").

### Определи объем выхлопа
Тебе нужна только одна функция? Полный файл или модуль? Тесты нужны? Например, "Дай только реализацию функции" и "Дай полный запускаемый скрипт" дадут совершенно разные ответы.

### Включи требования и ограничения
В примере с логином мы указывали длину пароля и лимит попыток. Подумай о граничных случаях или ограничениях и запихни их в промт. Если код должен быть оптимизирован по производительности или использовать определенный алгоритм, скажи об этом: "используя время O(n) и память O(1)" или "используя подход бинарного поиска".

### Избегай двусмысленных ссылок
Не используй слова типа "это/его" без четкого контекста. Вместо "Обработай это и верни результат", скажи: "Обработай массив и верни результирующий массив".

### Назови желаемый формат ответа
Если ты хочешь, чтобы ИИ выдал только код, или код с комментами, или объяснение, ты можешь это прописать: "Дай только код, без объяснений" или "Предоставь код и краткий коммент к каждому шагу".

Четкий промт настраивает ИИ на успех. Если ты замечаешь, что ответы ИИ часто приходится жестко править, проверь, не слишком ли размыты твои запросы.

А вот чего делать **не надо**:

### Не пиши гребаные романы
Длинные простыни текста с кучей лишней инфы могут сбить модель с толку или заставить её сфокусироваться не на том. Будь краток, но полон в описании. Например, тебе обычно не нужно начинать с "Ты — программист мирового класса..." в контексте кодинга (некоторые делают так в обычном ChatGPT, но для задач по коду это часто лишний шум).

### Не надейся, что ИИ сам правильно додумает детали
Если что-то важно (типа потокобезопасности, обработки спецсимволов и т.д.), упомяни это. Если не упомянул — считай, что ИИ это проигнорит.

### Избегай открытых "креативных" промтов, когда нужен детерминированный результат
Например, фраза "Напиши какой-нибудь код для анализа данных" заставит ИИ гадать, какой именно анализ ты хочешь. Вместо этого уточни:

> Рассчитай среднее и стандартное отклонение списка чисел.

Короче, говори именно то, что имеешь в виду. Чем больше ИИ "знает" о том, что ты реально хочешь, тем лучше он справится. Если ловишь себя на том, что правишь ИИ по десять раз, спроси себя: мог ли мой изначальный промт быть понятнее?

## Итеративное улучшение: Петля обратной связи с ИИ

Даже с четкими промтами ты не всегда получишь идеальный ответ с первого раза. Воспринимай взаимодействие с ИИ как разговор или итеративный процесс разработки. Это та самая петля обратной связи, о которой я заикнулся в Главе 1.

Когда ИИ выдает тебе код, проверяй его критически, так же, как код, написанный человеком. Соответствует ли он требованиям? Если нет, найди, чего не хватает или где косяк. Затем дай фидбек или уточни промт. Это можно сделать в чате, просто продолжив диалог, или в редакторе, написав еще один коммент, на который ИИ ответит.

Давая обратную связь ИИ, ты рулишь им в сторону нужного результата. В каком-то смысле, ты тренируешь его на лету под свою конкретную проблему. Продвинутый промт-инжиниринг похож на цикл на Рисунке 2-2: Промт → Ответ ИИ → Ревью → Уточнение промта → Ответ ИИ → ...пока не будешь доволен. Полезно делать изменения в каждой итерации небольшими; если перелопатишь промт слишком сильно, можешь потерять хорошие куски из предыдущего ответа.

> [!NOTE]
> **Image Missing**
> *Рисунок 2-2. Цикл продвинутого промт-инжиниринга.*

Например, ты пишешь:

> Напиши функцию, которая принимает список целых чисел и возвращает их сумму.

ИИ возвращает функцию, но код предполагает, что список не пустой, и ломается на пустом списке. Ты можешь ответить:

> Выглядит норм. Однако, поправь её так, чтобы она возвращала 0, если список пуст.

ИИ обновит функцию соответствующим образом. Таким макаром тебе не пришлось писать промт с нуля; ты просто сказал ИИ внести правку. У ИИ уже был контекст предыдущего кода.

Если ты используешь встроенного ассистента (inline), уточнение может выглядеть как редактирование кода и, возможно, написание коммента типа `# TODO: обработать пустой список`, чтобы посмотреть, предложит ли ИИ фикс.

Другой подход к уточнению — переспросить с большим количеством инфы, если первый выхлоп был мимо. Допустим, ты сказал: "Отсортируй список имен", и он дал код с сортировкой, чувствительной к регистру, а тебе нужно без учета регистра. Ты можешь перефразировать:

> Отсортируй список имен без учета регистра.

Или даже:

> Предыдущий код сортирует с учетом регистра. Измени его, чтобы было без учета регистра.

В отладке, для более сложных логических багов (где нет явной ошибки, но результат кривой), можно попросить ИИ пройтись по выполнению кода. Например:

> Пройдись по этой функции построчно и отслеживай значение переменной total на каждом шаге. Она накапливается неправильно — где логика сворачивает не туда?

Это пример промта для отладки методом "резиновой уточки": ты, по сути, просишь ИИ симулировать процесс отладки, который делал бы человек с принтами или дебаггером. Такие промты часто вскрывают неочевидные проблемы, типа несброшенных переменных или кривых условий, потому что ИИ проговаривает состояние на каждом шаге. Если подозреваешь конкретную часть кода, можешь зумить туда:

> Объясни, что здесь делает вызов filter, и может ли он исключать больше элементов, чем нужно.

Вовлечение ИИ в роль "объяснятора" может выявить баг прямо в процессе объяснения.

После объяснения часто эффективно прямо попросить то, что нужно:

> Что может вызывать эту проблему и как мне это пофиксить?

Это приглашает ИИ и поставить диагноз, и предложить лекарство. Если первый ответ ИИ мутный или помог лишь частично, не стесняйся задать уточняющий вопрос:

> Объяснение логичное. Можешь показать, как исправить код? Пожалуйста, дай исправленный вариант.

В чате у ИИ есть история переписки, так что он может сразу выдать модифицированный код. Если используешь inline-инструмент типа Copilot в VSCode или Cursor без чата, можешь написать коммент над кодом:

`// BUG: возвращает NaN, исправь эту функцию и посмотри, как она автодополнится`

Но в целом, интерактивный чат дает более глубокие объяснения.

Еще один паттерн для фоллоу-апа: если ИИ дает фикс, но ты не вдупляешь почему, спроси:

> Можешь объяснить, почему это изменение решает проблему?

Так ты учишься на будущее и перепроверяешь, что логика ИИ здоровая.

LLM-ки обожают примеры и исправления. Если ты указываешь на ошибку или даешь быстрый пример, ИИ может это впитать:

> Если вход [], должно возвращать 0, но сейчас падает с ошибкой.

Этот итеративный процесс — норма. На самом деле, попытка впихнуть каждую деталь в один мега-промт может быть менее эффективной, чем пара ходов "туда-сюда". Используй это.

Будь терпелив и конкретен в своем фидбеке. Вместо того чтобы говорить "Нет, это неправильно", скажи, что именно не так или что нужно:

> Этот код неправильно обрабатывает отрицательные числа. Он должен считать их за 0 в сумме.

Также, если ИИ понесло не туда, ты можешь вернуть его на рельсы: иногда проще сбросить контекст или перефразировать, чем пытаться спасти совсем уж кривую попытку. Смотри по ситуации. Если ответ ИИ показывает, что он вообще тебя не понял, перепиши промт с нуля.

В процессе допиливания ты также поймешь, как ИИ интерпретировал твой промт. Это поможет писать будущие запросы лучше. Ты можешь осознать: "А, он воспринял 'система логина' как весь UI целиком. В следующий раз уточню, что нужен только бэкенд".

Думай об этом как об отладке кода: если выхлоп ИИ неверен, "баг" может быть в твоем промте, а не в мозгах ИИ. Точно так же, как ты бы искал ошибки в своем коде при неверном результате, тебе стоит рефакторить свои промты, когда ИИ генерит дичь. Разговор между тобой и ИИ — это сессия отладки, где каждый обмен репликами помогает найти и устранить проблему.

## Сравнение двух промтов

Представь, что у тебя есть простая Node.js функция, которая должна конвертировать список объектов пользователей в карту (lookup map) по ID пользователя. Но она кидает ошибку. Вот забагованный код:

```javascript
// Забагованная функция: конвертирует массив юзеров в карту по ID
function mapUsersById(users) {
  const userMap = {};
  for (let i = 0; i <= users.length; i++) {  
    // Примечание: использование <= приведет к выходу за границы на последней итерации
    const user = users[i];
    userMap[user.id] = user;
  }
  return userMap;
}

// Пример использования:
const result = mapUsersById([{ id: 1, name: "Alice" }]);
```

Этот код должен пробежаться по массиву юзеров и собрать объект, где ключи — это ID юзеров. Однако тут есть баг: цикл использует `i <= users.length` вместо `i < users.length`. Это приведет к тому, что `users[i]` будет `undefined` на последней итерации, что, скорее всего, вызовет ошибку рантайма (типа попытки доступа к свойству ID у `undefined`). Давай посмотрим, как ИИ-ассистент может ответить на два разных промта об этой проблеме (см. Рисунок 2-3).

> [!NOTE]
> **Image Missing**
> *Рисунок 2-3. Сравнение влияния качества промта: мутные промты дают дженерик-ответы или неверный код, в то время как конкретные, хорошо структурированные промты генерируют точные, подходящие по контексту решения.*

### Плохой промт

Вот пример хренового промта:

> Почему моя функция mapUsersById не работает?

Ответ ИИ на плохой промт (симуляция):

> Трудно сказать без дополнительной информации. Вы уверены, что функция вызывается с правильным массивом пользователей? Возможно, проблема в том, что `users` пуст или не является массивом, из-за чего цикл не выполняется корректно. Также может быть ошибка при установке свойства в `userMap`. Убедитесь, что у каждого пользователя есть свойство `id`. Если `users` равно `undefined` или `null`, это тоже приведет к неработоспособности.

Этот ответ довольно размытый. Промт не дал никаких деталей, кроме имени функции, поэтому ИИ гадает на кофейной гуще, предлагая общие причины ("Может, массив пустой", "Убедитесь, что у каждого юзера есть ID"). Он не нашел реальный баг.

Это тот тип ответа, который ты получаешь, когда вопрос недоопределен — модель может только выдать набор банальных советов по отладке. Если ты разраб, это не особо помогает, потому что не решает реальную проблему. Нехватка контекста и конкретики в промте дает дженерик-ответ: по сути, ИИ-эквивалент фразы "А вы пробовали выключить и включить?". Это подтверждает общее правило: мутные промты ведут к бесполезным или общим ответам.

### Улучшенный промт

Давай попробуем еще раз:

> У меня есть JavaScript функция `mapUsersById`, которая должна конвертировать массив объектов пользователей в карту (объект) с ключами по ID пользователя. Однако она кидает ошибку при запуске. Например, когда я передаю `[ {id: 1, name: "Alice"} ]`, я получаю `TypeError: Cannot read property 'id' of undefined`. Вот код функции:
>
> ```javascript
> function mapUsersById(users) {
>   const userMap = {};
>   for (let i = 0; i <= users.length; i++) {  
>     const user = users[i];
>     userMap[user.id] = user;
>   }
>   return userMap;
> }
> ```
> Она должна возвращать `{ "1": {id: 1, name: "Alice"} }`. В чем баг и как мне его исправить?

Ответ ИИ на улучшенный промт (симуляция):

> Ошибка `Cannot read property 'id' of undefined` подсказывает, что в какой-то момент `user` становится `undefined`, и затем вы пытаетесь обратиться к `user.id`. Глядя на ваш цикл, проблема в границах цикла. Вы используете `i <= users.length`. Если `users.length` равно 1 (для одного юзера в массиве), цикл выполняется для `i = 0` и `i = 1`. Когда `i` равно 1, `users[1]` будет `undefined` (так как единственный индекс в массиве — 0). Таким образом, `user` становится `undefined` на этой итерации, и `user.id` вызывает `TypeError`. Исправление — изменить условие цикла на `i < users.length`, чтобы `i` шло от 0 до `users.length-1`. Например:
>
> ```javascript
> for (let i = 0; i < users.length; i++) {
>   const user = users[i];
>   userMap[user.id] = user;
> }
> ```
> Таким образом, `i` будет 0 для первого (и единственного) элемента, и затем цикл остановится. С этим изменением ваша функция больше не наткнется на `undefined` user и должна работать как ожидается, возвращая `{"1": {id: 1, name: "Alice"}}` для данных входных параметров.

Этот ответ прямо указывает на баг (использование `<=` в цикле) и объясняет, почему это приводит к `undefined`. Затем он дает правильное решение в коде (`i < users.length`) и подтверждает ожидаемый результат. Улучшенный промт сработал, потому что следовал нашим принципам: он указал язык (JavaScript), описал цель функции, включил точное сообщение об ошибке и пример входных данных, и даже предоставил сам кусок проблемного кода.

Зацени, как ИИ использовал сообщение об ошибке как зацепку, чтобы сфокусироваться на границах цикла — целевой промт позволил ИИ заняться реальным решением проблем, эффективно симулируя ход мыслей человека-дебаггера: "Откуда может взяться `undefined`? Скорее всего, из индексации цикла". Это наглядная демонстрация пользы детальных промтов.

## Техники промтинга: Ящик с инструментами для эффективного общения

Теперь давай перейдем к конкретным техникам, которые могут прокачать твои скиллы промтинга. Это как паттерны или рецепты, которые можно использовать, когда простой инструкции недостаточно или когда ты хочешь направить ИИ в определенное русло.

Освоив эти техники, ты сможешь разруливать кучу ситуаций: инструктировать ИИ простым языком, давать ему примеры, заставлять его объяснять или структурировать свой ответ, или задавать ему разные майндсеты или роли. Всё это поможет тебе заставить ИИ выдать именно то, что тебе нужно.

Техники промтинга не исключают друг друга; часто ты будешь использовать несколько сразу для наилучшего результата, особенно на сложных задачах.
## Заметка о стиле
Когда юзаешь эти техники, подстраивай тон под модель. Многие сетки отлично реагируют на вежливые или нейтральные инструкции. Не надо включать режим "джентльмена из 19 века" или писать канцелярщиной. Прямота с налетом вежливость работает на ура: "Пожалуйста, сделай X" или "Давай запилим Y". Например, для промптинга с цепочкой мыслей (CoT) коронная фраза — "Давай подумаем пошагово" (Let’s think step-by-step). Модели типа GPT-4 воспринимают это как триггер, чтобы включить логику и показать ход мыслей.

## Зеро-шот промптинг (Zero-Shot Prompting)
Зеро-шот — это когда ты просишь модель что-то сделать в лоб, без всяких примеров и лишних наводок, кроме самой инструкции. По сути, модель решает задачу с "нулем" примеров перед глазами.

**Когда юзать:** Самый частый сценарий. Ты просто просишь то, что тебе нужно, обычным человеческим языком. Если задача стандартная, а промпт четкий — этого обычно хватает за глаза.

**Пример:**

> Напиши функцию на Python, которая проверяет, является ли число простым.

Это зеро-шот. ИИ, скорее всего, выплюнет функцию проверки простоты через цикл или перебор делителей.

**Плюсы:** Быстро и работает на "мышечной памяти" модели. Современные сетки удивительно хороши в зеро-шот режиме для кучи задач по кодингу, особенно если это классика (типа проверки простых чисел, сортировки или возни со строками).

**Минусы:** Если задача с подвывертом или нужен специфический формат вывода, зеро-шот может выдать результат, который не совсем "в кассу" с первого раза, потому что у модели слишком много вариантов интерпретации.

Обычно хорошая тактика — попробовать зеро-шот для простых вещей. Если результат кривой — переходишь к уточнению или другим техникам.

## Ван-шот и Фью-шот промптинг (One-Shot and Few-Shot)
Ван-шот (one-shot) — это когда ты скармливаешь ровно один пример того, что хочешь (входные данные и желаемый результат) прямо в промпте. Фью-шот (few-shot) — это когда даешь несколько примеров (обычно от двух до пяти), прежде чем попросить модель сделать то же самое с новыми данными.

Это как показать джуну: "Смотри, вот так я решил одну задачу. Теперь сделай следующую по аналогии".

**Когда юзать:** Эта техника — мастхэв, когда модель может не догнать формат или стиль, который тебе нужен, или когда задача немного нестандартная. Давая примеры, ты убираешь двусмысленность.

**Пример (ван-шот):** Допустим, ты используешь язык или стиль, который модель видела не так часто. Скажем, тебе нужен псевдокод в специфическом формате. Твой промпт может выглядеть так:

> Конвертируй следующие инструкции на английском в Python-подобный псевдокод.
>
> Пример инструкции: "Вычислить факториал числа n":
>
> Пример псевдокода:
>
> ```text
> function factorial(n):
>
>     if n <= 1:
>
>         return 1
>
>     else:
>
>         return n * factorial(n-1)
> ```
>
> ## Инструкция: "Найти самое большое число в списке"
>
> Псевдокод:

Ты дал один пример (факториал) и показал формат. Теперь модель с гораздо большей вероятностью выдаст псевдокод для "самого большого числа" в том же стиле (с функцией, с if/else или циклом, как положено).

**Пример (фью-шот):** Допустим, ты хочешь, чтобы ИИ использовал конкретный алгоритм. Ты можешь подкинуть ему пример этого алгоритма в действии как подсказку. Или, если у задачи есть несколько правильных ответов, но ты предпочитаешь определенный стиль, пример подтолкнет ее в нужную сторону.

Фью-шот промптинг — мощная штука для форматирования. Например:

> Преобразуй следующие фразы на английском в SQL-запросы.\
> 1. "Получить всех сотрудников, нанятых после 2020 года" → Select * From Employees Where Hire_Date > ’2020-01-01’;\
> 2. "Список имен клиентов, совершивших покупку в прошлом месяце" → Select Name From Customers Join Purchases On ... Where Purchase_Date > ...;\
> 3. "Количество товаров, которых нет в наличии" →

Здесь, дав два примера перевода с английского на SQL, ты практически гарантируешь, что ИИ правильно ответит на третий запрос, следуя паттерну. Фью-шот примеры применимы и к кодингу: покажи ИИ нужный стиль на маленьком куске и попроси добавки. Это как скормить ей мини-датасет для обучения прямо внутри промпта.

**Плюсы:** Можно добиться вывода в очень специфическом стиле. Эта техника помогает модели справляться с задачами, где нужно следовать шаблону или монотонно применять какую-то концепцию.

## Контекстное окно (Context Window)
Термин "контекстное окно" означает максимальный объем текста (в токенах), который языковая модель может переварить за один заход — включая и твой промпт, и ее ответ. Это жесткое ограничение текущих ИИ: как только перевалишь за порог, модель перестает воспринимать новую инфу или забывает начало. Когда крафтишь промпты, всё, что ты туда пихаешь (инструкции, примеры, данные и место под ответ), должно влезать в эту емкость.

**Минусы:** Фью-шот промптинг, в частности, раздувает промпт (что жрет контекстное окно). Если примеры жирные и сложные, они могут сожрать кучу места. Но обычно пары небольших примеров вполне достаточно.

**Совет:** Если хочешь, чтобы модель строго придерживалась определенной структуры вывода, пример почти гарантирует, что она попадет в формат, вместо того чтобы выдавать отсебятину, которую тебе потом придется парсить руками.

## Цепочка мыслей (Chain-of-Thought Prompting)
Chain-of-thought (CoT) — это когда ты просишь модель думать пошагово или показать ход рассуждений перед тем, как выдать финальный ответ. Другими словами, ты заставляешь модель декомпозировать проблему.

**Когда юзать:** Полезно для сложных задач, требующих логики и многоступенчатых вычислений, или когда есть подозрение, что модель налажает, если попытается прыгнуть сразу к ответу. Также полезно, если тебе нужно объяснение в выводе.

## Комбинаторика
Комбинаторика занимается подсчетом, расстановкой и выбором объектов по определенным правилам. Типичные задачи включают перестановки (порядок важен), сочетания (порядок пофиг) и прочие принципы счета. Ключевая нотация — "n по k" (записывается как C(n,k) или nCk), что означает количество способов выбрать k предметов из n, по формуле n!/(k!(n-k)!). Эти расчеты постоянно всплывают в вероятности, статистике и дискретной математике.

**Пример:** Вместо того чтобы просто спросить комбинаторную задачу типа "Сколько будет 12 по 4?" и получить голую цифру, ты можешь сказать:

> Реши "12 по 4" пошагово.

Модель может расписать:

> 12 по 4 = 12!/(4!*8!) = ... = 495

В кодинге CoT полезна для хитрых алгоритмических задач. Попробуй такой промпт:

> Объясни пошагово, как слить два отсортированных списка, а затем предоставь код на Python.

Модель сначала накидает план типа:

> Мы будем использовать два указателя, начиная с голов каждого списка, сравнивать элементы, добавлять меньший в результирующий список, двигать указатель и так далее…

А потом выдаст код. Это гарантирует, что она нормально структурировала решение перед тем, как кодить.

Еще один юзкейс — отладка или понимание вывода:

> Пройдись по логике, чтобы определить, является ли число 19 простым, затем дай результат.

Модель перечислит деления на простые числа, а потом заключит:

> 19 — простое число.

**Плюсы:** Повышает правильность на задачах, требующих рассуждений. Есть научные пруфы, что если заставить модель "думать вслух", результаты по математике и логике становятся лучше. Плюс ты видишь процесс, что может быть поучительно или поможет больше доверять ответу.

**Минусы:** Вывод становится длиннее (что может быть некстати, если нужен только код). Также некоторые интерфейсы (типа автодополнения кода) не заточены под показ рассуждений отдельно от кода. Эта техника чаще встречается в чатах. Однако ты можешь попросить модель включить рассуждения в виде комментариев в коде — отличный способ получить шикарно задокументированный код.

## Ролевой промптинг (Role Prompting)
Ролевой промптинг — это когда ты просишь ИИ примерить на себя определенную личину или роль, которая повлияет на то, как он отвечает.

**Когда юзать:** Полезно, когда хочешь повлиять на стиль, детализацию ответа или получить определенную точку зрения. Например, ИИ в роли "эксперта" может выдать более продвинутое решение или глубокое объяснение, а в роли "новичка" — разжевать базовые концепции.

**Примеры:**

> Ты — инструктор по Python. Объясни следующий код, а затем модифицируй его, чтобы он был более "питоничным" (Pythonic).

> Действуй как аналитик по безопасности. Вот код. Найди любые уязвимости.

> Притворись, что ты линтер, который проверяет код на проблемы со стилем.

Это может кардинально изменить ответ. Назначение роли "безопасника" заставит ИИ сфокусироваться на вещах, о которых он иначе бы промолчал (валидация данных, безопасные практики, потенциальные дыры). Роль "инструктора" заставит давать более четкие объяснения и не полагаться на то, что ты и так всё знаешь.

В кодинге ты можешь сказать перед запросом кода:

> Ты эксперт по C++, хорошо разбирающийся в оптимизации, инструктирующий младшего разработчика.

Результат, скорее всего, будет использовать продвинутые фичи C++ и объяснять, почему были сделаны те или иные выборы, балансируя между технической крутостью и понятностью для обучения.

**Плюсы:** Эта техника рулит тоном и глубиной ответа. Можно заточить решение под определенный уровень сложности. Полезно, если нужно либо очень простое решение (скажи ему действовать как новичок, и он, возможно, избежит сложных трюков), либо очень оптимизированное (скажи действовать как гуру перформанса).

**Минусы:** Иногда модель может слишком увлечься персоной (типа "инструктор" начнет объяснять банальщину). Также некоторые системы безопасности ИИ нервно реагируют на определенные описания ролей — особенно те, что намекают на обман, выдачу себя за авторитетов или вредоносные действия — хотя обычные технические роли типа "аналитик данных" или "разработчик ПО" обычно заходят без проблем.

## Контекстный промптинг (Contextual Prompting)
Контекстный промптинг — это когда ты даешь ИИ дополнительный контекст или инфу помимо описания задачи. У моделей нет постоянной памяти о твоем проекте, пока ты не запихнешь это в промпт (или через интеграции в IDE с умным контекстом). Так что, если хочешь, чтобы ИИ писал код, который впишется в твою кодовую базу — дай ему этот контекст. Грубо говоря, ты скармливаешь релевантные данные или бэкграунд прямо в запросе.

**Когда юзать:** Когда решение задачи требует знания определенных данных или определений, которые модель может не знать или помнить криво. Или когда нужно обеспечить согласованность с внешней инфой (типа спецификации API или предыдущей части разговора).

**Примеры:**

Если у тебя есть структура данных и ты хочешь код, который с ней работает, просто вставь ее определение:

> Учитывая класс ниже, реализуй функцию X.
>
> ```python
> class Node:
>
>     def __init__(self, value, next=None):
>
>         self.value = value
>
>         self.next = next
> ```
>
> \# А теперь напиши функцию для подсчета узлов в связном списке, начиная с head.

Включив определение класса, ты делаешь так, что ИИ с гораздо большей вероятностью будет правильно использовать `Node.value` и `Node.next` в своем коде.

Если хочешь использовать конкретный API, включи сниппет из документации в промпт:

> Используя библиотеку requests, получи данные из API. (API возвращает JSON в формате: {...})

Если ты покажешь даже короткий пример использования API из доков, ИИ сможет его сымитировать.

Для устранения неоднозначности:

> Используя термин "студент" для обозначения учеников старших классов, напиши функцию, которая…

Если слово "студент" может быть понято двояко в контексте, ты это прояснил.

**Плюсы:** Ты "заземляешь" ИИ в контексте, который тебе важен. Меньше шансов, что он сделает неверные предположения, если ты дашь ему факты. Это мега-полезно, если ИИ иначе не мог бы знать детали твоего конкретного юзкейса.

**Минусы:** Эта техника делает промпты длиннее. Также модель может иногда тупо срыгнуть предоставленный контекст обратно в ответе (например, скопипастить строки из сниппета доков в код, если не быть осторожным). Но обычно она юзает это адекватно.

**Совет:** Если контекст огромный (типа здоровенной схемы или кучи строк кода), иногда лучше скормить модели саммари ключевых элементов, а не всё дословно. Это поможет остаться в лимитах контекста, при этом дав модели самую суть. Но если контент небольшой — кидай сырым.

Ограничения (Constraints) тоже полезно упоминать: требования к производительности ("Оптимизируй под O(n log n) или лучше"), совместимости ("Должно работать на Python 3.8") или выбор библиотек ("Используй только стандартную библиотеку, никаких внешних зависимостей"). Это работает как отбойники на трассе и гарантирует, что ИИ не предложит что-то за рамками дозволенного.

## Метапромптинг (Metaprompting)
Метапромптинг — это инструкции касательно самого вывода, а не только того, что должно делать решение. Это как указывать ИИ, как отформатировать или подойти к решению.

**Когда юзать:** Полезно, когда нужен ответ в конкретном формате или стиле, или когда хочешь контролировать, как ИИ прорабатывает проблему.

**Примеры:**

> Сначала объясни подход в двух предложениях, затем предоставь код.

Это гарантирует, что ИИ не бросится сразу писать код.

> Не используй никакие библиотеки в решении.

Это ставит ограничение на решение.

> Отформатируй вывод как JSON.

Полезно, если ты используешь ИИ для генерации данных, а не кода.

> Предоставь только тело функции, без строки определения.

Удобно, если хочешь вставить функцию в существующий код.

> Если ввод невалиден, вместо ошибки верни None.

Это не совсем формат вывода, но инструкция ИИ, как вести себя в определенных кейсах.

**Плюсы:** Ты получаешь именно то, что нужно, и так, как нужно, без лишнего редактирования. Это критично для некоторых сценариев. Если планируешь автоматически скармливать вывод ИИ в пайплайн, тебе реально нужно стабильное форматирование.

**Минусы:** Если инструкции конфликтуют с дефолтным стилем модели, иногда она может следовать им лишь частично, или придется их подчеркивать. Например, даже если скажешь "только код, никаких объяснений", иногда модель может вставить крошечный коммент. Обычно помогает прямая императивная фраза:

> Не включай никаких объяснений; выводи только код внутри одного блока кода.

Модели типа GPT следуют этому довольно четко.

## Самосогласованность (Multiple Outputs and Majority Voting)
Самосогласованность (Self-consistency) — это скорее стратегия, чем стиль промпта. Идея в том, чтобы получить несколько вариантов ответа на один и тот же промпт, а потом выбрать лучший или самый частый. Как отмечает Сандер Шульхофф из Learn Prompting, самосогласованность опирается на идею, что если спросить модель несколько раз (с легкой рандомизацией) и многие ответы совпадут, то этот консенсус, скорее всего, верен.

**Когда юзать:** Полезно для сложных проблем, где ты не уверен, что первый ответ модели правильный, особенно если сам не можешь легко проверить, или если хочешь чекнуть уверенность ИИ, посмотрев, выдаст ли он тот же ответ повторно.

**Как юзать вручную:** На некоторых платформах (типа ChatGPT) можно нажать "Regenerate answer". Или скопировать промпт в новую сессию и посмотреть, даст ли тот же результат. Если получишь три ответа, и два из них одинаковые, а один отличается — можно довериться тем двум (при условии, что у задачи один правильный ответ).

В контексте программирования, если генерится код для чего-то детерминированного, обычно он будет очень похож каждый раз (с мелкими вариациями в именах переменных или стиле). Но если это алгоритмический вопрос (типа "Какой будет вывод этого кода?"), можно прогнать несколько раз.

Эта техника мощнее в некодинговых задачах (типа логических пазлов), но знать о ней стоит.

Другой угол — ансамблевый промптинг: Ты можешь попросить модель прямо в одном промпте рассмотреть несколько вариантов:

> Дай два разных решения этой задачи.

Потом выберешь, какое больше нравится, или протестишь оба. Это как самосогласованность за один проход, потому что получаешь несколько ответов.

**Плюсы:** Эта техника может повысить уверенность в решении, если несколько попыток сходятся. Плюс, получаешь разнообразие (что хорошо, если хочешь выбрать самое элегантное решение из многих).

**Минусы:** Жрет время на генерацию и сравнение.

На практике, если я не уверен в ответе, я часто переформулирую вопрос по-другому, чтобы увидеть, получу ли я тот же ответ. Если да — уверенности больше.

## ReAct (Reason + Act) Промптинг
ReAct — это более продвинутая техника, объединяющая рассуждения (Reasoning) и действия (Acting). Она заставляет модель не просто думать, как CoT, но и совершать действия: делать расчеты, дергать API или юзать инструменты. (См. гайд по ReAct Prompt Engineering для подробностей). В современной практике это часто используется с фреймворками типа LangChain, где ИИ может выдавать спецформат, который программа интерпретирует как действие (команда на выполнение или запрос), а потом скармливает результат обратно.

Для наших целей (без среды выполнения в цикле) ты все равно можешь использовать форму ReAct, инструктируя ИИ сначала набросать план, а потом выдать результат. Это похоже на CoT, но заточено конкретно под использование инструментов или выполнение подзадач.

**Пример:**

> Используя Python, определи текущую погоду в Париже и выведи её.

Если у ИИ нет доступа в инет, он не сможет реально узнать погоду. Подход ReAct заставил бы ИИ сначала порассуждать:

> Мне нужно получить данные о текущей погоде в Париже, для чего требуется вызов погодного API.

Затем ИИ попытался бы использовать доступный инструмент для вызова API. Если успешно — получил бы реальные данные; если инструмента нет — признал бы ограничение или работал с гипотетическими данными. В конце ИИ написал бы код на Python для отображения погоды, используя данные, полученные в процессе этого рассуждения и действия.

Без доступа к внешним инструментам ReAct может быть не особо актуален для простых задач. Однако при оценке ИИ-тулзов для твоей конторы, способность лазить в инет за свежей инфой — критический критерий. У многих моделей есть "дата отсечения" знаний, так что они могут выдавать протухшую инфу по быстро меняющимся темам.

Если ты сидишь в среде, где ИИ может исполнять код (типа интеграций с Jupyter), ты мог бы реализовать ReAct, скомандовав:

> Сначала напиши тест для этой функции, запусти его, а затем поправь код соответственно.

Это демонстрирует паттерн ReAct через шаг рассуждения (написание теста), за которым следует действие (запуск теста) и правка кода по результатам. Но дирижировать такими воркфлоу чисто через промпты требует продвинутых техник и соответствующей инфраструктуры.

Вариант попроще: Можешь симулировать Q&A, где у ИИ есть промежуточные шаги, имитирующие действия:

> Думай пошагово и, если нужно, делай вычисления.

Это, по сути, CoT, но с более императивным тоном.

**Плюсы:** Когда доступно, может решать задачи, требующие внешней инфы или итеративных проб (типа ИИ сам себя правит, реально запуская код). В отладке ИИ, который может запустить код для проверки — это фантастика.

**Минусы:** Эта техника малодоступна без спец-тулзов. А если просто промптить так в голом ChatGPT, он будет либо галлюцинировать действия, либо просто делать CoT.

Для наших целей в написании промптов держи в голове, что некоторые системы (типа агентов OpenAI с инструментами) существуют, но в "ванильном" промптинге мы в основном юзаем CoT, а действия типа запуска кода или тестов делаем сами ручками.
## Продвинутый промптинг: Миксуем техники и разгребаем сложность

Техники промптинга можно и нужно комбинировать. Например, ты можешь закинуть **few-shot** промпт, где в примерах уже зашита логика **CoT** (цепочки рассуждений). Или объединить ролевую модель с CoT:

> Как сеньор-разработчик, продумай решение проблемы шаг за шагом, а затем выдай готовый код.

Теперь, когда мы разобрали разные техники, давай глянем на них в бою на паре сценариев, а потом обсудим, как ревьюить и допиливать то, что выплюнул AI (это плавно подведет нас к следующей главе про понимание и владение сгенерированным кодом).

Представь, что у тебя есть функция, которая ни хрена не работает. Тут идеально зайдет комбо из роли и CoT:

> Ты — Python-дебаггер. Давай шаг за шагом проанализируем следующий код, чтобы найти баг.

Следом кидаешь сам код. В ответ сетка, скорее всего, разберет каждую строчку и ткнет пальцем в ошибку.

Или, допустим, тебе нужно сгенерировать код для довольно сложного алгоритма, убедиться, что он нормально закомментирован, да еще и тесты к нему получить. Комбинированный промпт будет выглядеть примерно так:

> Ты — эксперт-разработчик на Python. Давай решим задачу пошагово. Нам нужна функция `merge_sorted_lists(list1, list2)`, которая сливает два отсортированных списка в один. Сначала объясни подход, затем предоставь код на Python с комментариями. После этого напиши 2–3 примера тестов в коде, чтобы показать, что всё работает.

Этот единственный промпт охватывает всё. Первое предложение задает роль. Второе требует пошагового мышления. Третье ставит основную задачу. Четвертое просит код с пояснениями, а пятое даже требует тесты.

AI, скорее всего, выдаст объяснение, затем код с инлайн-комментами, а в конце прилепит тест-кейсы. Это продвинутый уровень, но он показывает, как можно дирижировать нейронкой, чтобы получить многогранный ответ.

## Знай лимиты своей железяки

Промпт-инжиниринг — это еще и умение понимать, чего просить **не** стоит и как не наступить на грабли. Если промпт раздувается до неприличия или содержит слишком много инструкций, модель может поплыть или обрезать часть выхлопа. Если видишь, что она начинает игнорить куски твоего задания — упрощай или скармливай частями.

Если AI начинает гнать пургу (фактические ошибки или битый код, он же "галлюцинирует"), учись перепроверять всё и не используй его как истину в последней инстанции. Если он любит писать "Войну и мир" вместо кода — пресекай это фразой "Сделай решение максимально кратким". Если использует функции, которых в природе не существует — дай команду: "Используй только API функции из списка ниже" и приложи список. Чем лучше ты выкупаешь поведение AI, тем легче тебе лепить промпты, обходящие его слабости.

Если задача реально сложная, разбей ее на подзадачи. Например, сначала спроси:

> Перечисли шаги для реализации базового компилятора для простого языка арифметических выражений.

Как только AI выдаст шаги, атакуй каждый пункт отдельным промптом, можно даже в разных файлах или сессиях:

> Теперь реализуй шаг 1: токенизация.

Это как системный дизайн, только с AI: ты набрасываешь структуру, а потом детализируешь каждый кусок. Это задействует способность нейронки помогать в планировании (а не только в кодинге).

## Диалог с контекстом (Stateful) vs. Ваншот-промптинг

В чате у тебя есть история переписки, то есть **состояние** (state). Ты можешь накапливать контекст, общаясь с AI. В IDE при автодополнении контекст — это в основном содержимое твоего файла и комменты. Оба варианта позволяют накапливать информацию, но по-разному.

Используй **диалог**, если нужно, чтобы AI помнил, о чем вы говорили раньше (например, для уточнения ответа).
Используй **свежие промпты** или контекст файла, если хочешь, чтобы он сфокусировался только на том, что важно прямо сейчас. Иногда полный сброс контекста помогает вылечить модель от зацикливания на какой-то ошибочной идее, которую она подцепила раньше.

Практикуясь с этими техниками, ты набьешь руку и поймешь, когда и что юзать:

*   Если важен **формат вывода** — давай примеры (few-shot) или четкие инструкции по форматированию.
*   Если **логика хитрая** — юзай CoT или "step-by-step".
*   Если **качество решения плавает** — задай роль (типа "бывалый инженер"), чтобы подтянуть стиль.
*   Если модель **тупит и не слушается** — разбей промпт на куски, упрости или используй более жесткие формулировки ограничений.

## Типичные антипаттерны промптинга и как их не словить

Не все промпты одинаково полезны. Мы уже видели кучу примеров, как надо, но не менее полезно знать антипаттерны — типичные косяки, которые ведут к убогим ответам. В этом разделе разберем частые факапы и как их лечить.

### Мутный промпт (The vague prompt)

Классика жанра: "Оно не работает, почини" или "Напиши что-нибудь, что делает X", без деталей. Вопрос "Почему моя функция не пашет?" обычно вызывает бесполезный ответ. Мутные промпты заставляют AI гадать о контексте, и на выходе ты получаешь либо общие советы, либо код не в тему.

Лечится просто: добавь контекста и конкретики. Если ты задаешь вопрос, а ответ похож на предсказание Магического шара ("А вы пробовали проверить X?"), остановись и перепиши запрос с деталями (текст ошибки, кусок кода, ожидаемый vs реальный результат). Хорошая практика — прочитать свой промпт и спросить себя: "Может ли этот вопрос относиться к десятку разных сценариев?". Если ответ "да" — промпт слишком размыт. Сделай его таким специфичным, чтобы он подходил только к твоей ситуации.

### Перегруженный промпт (The overloaded prompt)

Обратная проблема: просить AI сделать всё и сразу. Например:

> Сгенерируй полноценное Node.js приложение с аутентификацией, фронтендом на React и скриптами деплоя.

Или даже в меньшем масштабе:

> Пофикси эти 5 багов, а заодно добавь вот эти 3 фичи за один заход.

AI может попытаться, но, скорее всего, ты получишь кашу, недоделку или игнор части запроса. Даже если он сделает всё, простыню кода будет сложно проверить.

Лекарство — декомпозиция. Расставь приоритеты: делай одну вещь за раз, как мы говорили ранее. Так проще ловить ошибки и держать модель в фокусе. Если видишь, что в твоем промпте слишком много союзов "и", разбей его на отдельные шаги.

### Потерянный вопрос (Missing the question)

Иногда юзеры вываливают кучу инфы, но забывают задать вопрос или сказать, что им нужно. Просто кидают кусок кода и пишут: "Вот мой код". Это сбивает AI с толку — он не знает, чего ты хочешь.

Всегда добавляй четкий призыв к действию:

*   "Найди баги в коде выше."
*   "Объясни, что делает этот код."
*   "Заполни TODO в этом коде."

У промпта должна быть цель. Если просто кинуть текст без вопроса, AI начнет строить догадки (например, саммари кода вместо фикса). Убедись, что AI понимает, *зачем* ты показал ему этот код. Даже простое "Что тут не так?" или "Продолжай реализацию функции" дает направление.

### Размытые критерии успеха (Vague success criteria)

Это тонкий момент. Ты можешь попросить оптимизацию, но не определить, что такое "успех". Например, "Сделай эту функцию быстрее". Быстрее по какой метрике? Если AI не знает твоих ограничений, он может заняться микро-оптимизацией, которая не важна, или выбрать подход, который теоретически быстрее, но на практике — пшик. Или "Сделай код чище". "Чище" — понятие субъективное. Мы решали это, явно указывая цели: "убери дублирование", "улучши имена переменных" и т.д.

Фикс: квалифицируй или квантифицируй улучшение:

*   "Оптимизируй функцию, чтобы она работала за линейное время (сейчас квадратичное)."
*   "Отрефактори это, чтобы убрать глобальные переменные и использовать класс."

Короче, будь конкретен насчет того, какую проблему ты решаешь рефакторингом или фичей. Если оставишь слишком много свободы, AI может решить совсем не ту проблему, которая тебя парит.

### Игнор уточнений от AI

Иногда AI отвечает вопросом или предположением:

> Вы используете классовые компоненты React или функциональные?

> Я предполагаю, что входные данные — это строка. Подтвердите, пожалуйста.

Если ты проигноришь это и просто повторишь свой запрос, ты упустишь шанс улучшить промпт. AI сигнализирует, что ему не хватает инфы. Всегда отвечай на вопросы или уточняй промпт.

Кроме того, если ответ AI явно мимо (не так понял вопрос), не долби его тем же самым промптом. Остановись и перефразируй. Может, у тебя там двусмысленность или ты забыл что-то важное. Общайся как с человеком: если собеседник не понял, ты объясняешь по-другому. Делай так же с AI.

### Непоследовательность (Inconsistency)

Если ты постоянно меняешь стиль запросов или мешаешь форматы в кучу, модель может запутаться. Примеры: прыжки от первого лица к третьему в инструкциях или дикая смесь псевдокода с реальным кодом.

Старайся держать единый стиль внутри одного промпта. Если даешь примеры, четко их выделяй (используй тройные кавычки для кода, цитаты для ввода/вывода). Последовательность помогает модели правильно парсить твои намерения. И если у тебя есть предпочтительный стиль (скажем, ES6 против ES5), упоминай его постоянно, иначе в одном ответе получишь одно, а в следующем — другое.

### Мутные отсылки типа "код выше"

В чате, если ты пишешь "функция выше" или "предыдущий вывод", убедись, что ссылка понятна. Если диалог длинный и ты пишешь "Отрефактори код выше", AI может потерять нить или выбрать не тот кусок.

Надежнее либо снова процитировать код, либо явно назвать функцию, которую хочешь переделать. У моделей ограниченное окно внимания, и хотя многие LLM могут ссылаться на старые части разговора, явное указание контекста спасает от путаницы. Особенно если прошло время (или куча сообщений) с момента, когда код был показан.

## Итого и что дальше

Искусство промптинга — это итеративный и творческий процесс. Модели развиваются, бест-практис могут меняться (будущие модели, возможно, будут лучше понимать намерения с полуслова). Но фундаментальный принцип остается: общайся эффективно, и AI будет служить тебе лучше.

По сути, освоение промпт-инжиниринга похоже на изучение нового языка программирования — языка инструкций для AI. Это смесь технического писательства, дальновидности и интерактивной отладки самого вопроса. Но как только ты набьешь руку, AI реально начнет ощущаться как продолжение твоего мозга. Ты сможешь надежно вытаскивать решения, которые задумал (или даже те, которые еще не до конца придумал, но можешь направить AI на их открытие), с минимальным трением. Этот навык станет таким же базовым, как умение гуглить или юзать дебаггер — это часть скиллсета современного разработчика в эру вайб-кодинга.

Если AI может решить около 70% проблемы, как подходить к этому как к партнерству в кодинге? Глава 3 рассмотрит, как разработчики реально используют AI, и установит "золотые правила" вайб-кодинга.
